# 머신러닝 인터뷰 질문 및 답변

## 머신러닝이란 무엇이며, 어떻게 작동하나요?
<details>
  <summary>더보기</summary>
  **머신러닝:** 데이터에서 패턴을 학습하고, 이를 기반으로 예측이나 결정을 내리는 알고리즘입니다. 작동 원리는 데이터를 수집하고, 전처리한 후, 모델을 학습시키고, 평가 및 예측하는 과정으로 이루어집니다.
</details>

## 머신러닝의 주요 유형은 무엇인가요?
<details>
  <summary>더보기</summary>
  - **지도학습 (Supervised Learning):** 레이블이 있는 데이터를 학습하여 예측 모델을 만드는 것.
  - **비지도학습 (Unsupervised Learning):** 레이블이 없는 데이터를 학습하여 데이터의 구조나 패턴을 찾는 것.
  - **강화학습 (Reinforcement Learning):** 에이전트가 환경과 상호작용하며 보상을 최대화하는 행동을 학습하는 것.
</details>

## 지도학습이란 무엇인가요? 예시를 들어주세요.
<details>
  <summary>더보기</summary>
  **지도학습:** 입력 데이터와 이에 대응하는 정답이 있는 데이터를 학습하여 새로운 데이터에 대한 예측을 수행합니다. 예시: 이메일 스팸 필터링, 이미지 분류.
</details>

## 비지도학습이란 무엇인가요? 예시를 들어주세요.
<details>
  <summary>더보기</summary>
  **비지도학습:** 레이블이 없는 데이터를 학습하여 데이터의 구조나 패턴을 찾습니다. 예시: 클러스터링(고객 세분화), 차원 축소(Principal Component Analysis).
</details>

## 강화학습이란 무엇인가요? 예시를 들어주세요.
<details>
  <summary>더보기</summary>
  **강화학습:** 에이전트가 환경과 상호작용하며 보상을 최대화하는 행동을 학습합니다. 예시: 알파고(바둑 게임), 자율 주행 자동차.
</details>

## 분류와 회귀 문제의 차이점은 무엇인가요?
<details>
  <summary>더보기</summary>
  - **분류:** 데이터가 속하는 카테고리를 예측하는 문제입니다. 예시: 스팸 이메일 분류.
  - **회귀:** 연속적인 값을 예측하는 문제입니다. 예시: 주택 가격 예측.
</details>

## 머신러닝 모델에서 과적합과 과소적합을 설명해주세요.
<details>
  <summary>더보기</summary>
  - **과적합 (Overfitting):** 학습 데이터에 너무 잘 맞춰져 새로운 데이터에 대한 일반화 성능이 떨어지는 상태.
  - **과소적합 (Underfitting):** 모델이 학습 데이터의 패턴을 충분히 학습하지 못하여 성능이 낮은 상태.
</details>

## 편향-분산 트레이드오프란 무엇인가요?
<details>
  <summary>더보기</summary>
  **편향-분산 트레이드오프:** 모델의 복잡도와 예측 오류 간의 균형을 의미합니다. 편향이 높으면 과소적합, 분산이 높으면 과적합이 발생할 수 있습니다.
</details>

## 머신러닝에서 정규화의 개념을 설명해주세요.
<details>
  <summary>더보기</summary>
  **정규화 (Normalization):** 데이터의 범위를 일정한 범위로 변환하여 모델의 성능을 향상시키는 기법입니다. 주로 0과 1 사이로 변환합니다.
</details>

## 분류 문제에 대한 일반적인 평가 지표는 무엇인가요?
<details>
  <summary>더보기</summary>
  - 정확도 (Accuracy)
  - 정밀도 (Precision)
  - 재현율 (Recall)
  - F1 스코어 (F1 Score)
  - ROC-AUC (Receiver Operating Characteristic - Area Under Curve)
</details>

## 회귀 문제에 대한 일반적인 평가 지표는 무엇인가요?
<details>
  <summary>더보기</summary>
  - 평균 제곱 오차 (Mean Squared Error, MSE)
  - 평균 절대 오차 (Mean Absolute Error, MAE)
  - 결정 계수 (R²)
</details>

## k-폴드 교차 검증이란 무엇인가요?
<details>
  <summary>더보기</summary>
  **k-폴드 교차 검증:** 데이터를 k개의 폴드로 나누어 k번 학습 및 검증을 반복하는 방법입니다. 이를 통해 모델의 일반화 성능을 평가할 수 있습니다.
</details>

## 머신러닝에서 학습, 검증, 테스트 세트의 역할은 무엇인가요?
<details>
  <summary>더보기</summary>
  - **학습 세트:** 모델을 학습시키는 데 사용됩니다.
  - **검증 세트:** 모델의 하이퍼파라미터를 조정하거나 모델을 평가하는 데 사용됩니다.
  - **테스트 세트:** 학습 및 검증에 사용되지 않은 새로운 데이터로, 모델의 최종 성능을 평가합니다.
</details>

## 혼동 행렬의 목적을 설명해주세요.
<details>
  <summary>더보기</summary>
  **혼동 행렬 (Confusion Matrix):** 분류 모델의 성능을 평가하는 데 사용되며, 실제 값과 예측 값의 교차표를 나타냅니다. TP, TN, FP, FN 값을 통해 모델의 성능을 분석할 수 있습니다.
</details>

## 정밀도, 재현율, F1스코어의 차이점은 무엇인가요?
<details>
  <summary>더보기</summary>
  - **정밀도 (Precision):** 긍정 예측 중 실제로 긍정인 비율. TP / (TP + FP).
  - **재현율 (Recall):** 실제 긍정 중 모델이 긍정으로 예측한 비율. TP / (TP + FN).
  - **F1 스코어 (F1 Score):** 정밀도와 재현율의 조화 평균. 2 * (Precision * Recall) / (Precision + Recall).
</details>

## ROC 곡선과 AUC-ROC 점수란 무엇인가요?
<details>
  <summary>더보기</summary>
  **ROC 곡선 (Receiver Operating Characteristic Curve):** TPR(재현율)과 FPR(거짓 양성 비율)의 관계를 나타내는 그래프입니다.
  
  **AUC-ROC (Area Under Curve - ROC):** ROC 곡선 아래의 면적으로, 모델의 성능을 평가하는 지표입니다. 1에 가까울수록 좋은 성능을 나타냅니다.
</details>

## K-최근접 이웃(KNN) 알고리즘을 설명해주세요.
<details>
  <summary>더보기</summary>
  **K-최근접 이웃 (K-Nearest Neighbors, KNN):** 새로운 데이터 포인트의 클래스 또는 값을 예측하기 위해 가장 가까운 k개의 이웃 데이터 포인트를 참조하는 알고리즘입니다. 거리 기반으로 분류하거나 회귀할 수 있습니다.
</details>

## 의사결정트리의 작동 원리를 설명해주세요.
<details>
  <summary>더보기</summary>
  **의사결정트리 (Decision Tree):** 데이터를 분할하여 트리 구조를 만드는 알고리즘입니다. 각 노드는 특성에 따라 데이터를 분할하고, 리프 노드는 예측 값을 가집니다. 정보 이득, 지니 불순도 등을 사용하여 분할 기준을 결정합니다.
</details>

## 앙상블 방법과 배깅과 부스팅의 차이점은 무엇인가요?
<details>
  <summary>더보기</summary>
  **앙상블 방법 (Ensemble Methods):** 여러 개의 모델을 결합하여 성능을 향상시키는 방법입니다.
  
  - **배깅 (Bagging):** 여러 모델을 독립적으로 학습시켜 평균을 내는 방법입니다. 예: 랜덤 포레스트.
  - **부스팅 (Boosting):** 모델을 순차적으로 학습시켜 이전 모델의 오류를 보완하는 방법입니다. 예: Gradient Boosting, AdaBoost.
</details>

## 랜덤 포레스트 알고리즘을 설명해주세요.
<details>
  <summary>더보기</summary>
  **랜덤 포레스트 (Random Forest):** 여러 개의 의사결정트리를 학습시키고, 이를 결합하여 예측 성능을 향상시키는 배깅 기반 앙상블 방법입니다. 트리의 다양성을 위해 각 트리는 무작위로 선택된 데이터와 특성을 사용합니다.
</details>

## 그래디언트 부스팅 머신(GBM) 알고리즘을 설명해주세요.
<details>
  <summary>더보기</summary>
  **그래디언트 부스팅 머신 (Gradient Boosting Machine, GBM):** 이전 모델의 오류를 보완하는 방식으로 순차적으로 모델을 학습시키는 부스팅 방법입니다. 각 단계에서 손실 함수를 최소화하는 방향으로 모델을 추가합니다.
</details>

## 서포트 벡터 머신(SVM)에 대해 설명해주세요.
<details>
  <summary>더보기</summary>
  **서포트 벡터 머신 (Support Vector Machine, SVM):** 데이터를 분류하는 초평면을 찾는 지도학습 알고리즘입니다. 최대 마진을 가지는 초평면을 선택하여 데이터 포인트를 분류합니다.
</details>

## SVM에서 커널 함수란 무엇인가요? 예시를 들어주세요.
<details>
  <summary>더보기</summary>
  **커널 함수 (Kernel Function):** 데이터를 고차원 공간으로 변환하여 비선형 문제를 선형적으로 해결할 수 있게 합니다. 예시: 선형 커널, 폴리노미얼 커널, RBF 커널.
</details>

## SVM에서 하드 마진과 소프트 마진의 차이점은 무엇인가요?
<details>
  <summary>더보기</summary>
  - **하드 마진 (Hard Margin):** 데이터가 완벽하게 분리되는 경우의 마진입니다.
  - **소프트 마진 (Soft Margin):** 일부 오류를 허용하여 데이터가 완벽히 분리되지 않는 경우의 마진입니다.
</details>

## 신경망과 딥러닝의 관계를 설명해주세요.
<details>
  <summary>더보기</summary>
  **신경망 (Neural Network):** 인간의 뇌 구조를 모방한 알고리즘으로, 노드(뉴런)와 연결(시냅스)로 구성됩니다.
  
  **딥러닝 (Deep Learning):** 신경망을 다층으로 구성하여 복잡한 패턴을 학습할 수 있도록 한 기술입니다.
</details>

## 활성화 함수의 역할과 예시를 설명해주세요.
<details>
  <summary>더보기</summary>
  **활성화 함수 (Activation Function):** 뉴런의 출력을 비선형으로 변환하여 신경망이 복잡한 패턴을 학습할 수 있게 합니다. 예시: 시그모이드, 렐루(ReLU), 탄젠트 하이퍼볼릭(Tanh).
</details>

## 역전파 알고리즘의 원리를 설명해주세요.
<details>
  <summary>더보기</summary>
  **역전파 (Backpropagation):** 신경망의 학습 알고리즘으로, 출력 값과 실제 값의 오차를 최소화하기 위해 가중치를 조정합니다. 오차를 출력층에서 입력층으로 전파하면서 가중치를 갱신합니다.
</details>

## 드롭아웃이란 무엇이며, 어떤 목적으로 사용되나요?
<details>
  <summary>더보기</summary>
  **드롭아웃 (Dropout):** 학습 중 무작위로 일부 뉴런을 비활성화하여 과적합을 방지하는 정규화 기법입니다. 이를 통해 신경망이 더 일반화된 모델을 학습할 수 있습니다.
</details>

## 합성곱 신경망(CNN)의 구조화 원리를 설명해주세요.
<details>
  <summary>더보기</summary>
  **합성곱 신경망 (Convolutional Neural Network, CNN):** 이미지나 시계열 데이터와 같은 공간적 또는 시간적 패턴을 학습하는 데 특화된 신경망입니다. 합성곱층과 풀링층을 통해 특징을 추출하고, 완전 연결층을 통해 분류합니다.
</details>

## CNN에서 합성곱층의 역할은 무엇인가요?
<details>
  <summary>더보기</summary>
  **합성곱층 (Convolutional Layer):** 입력 데이터에 필터를 적용하여 특징 맵을 추출합니다. 각 필터는 데이터의 특정 패턴을 학습합니다.
</details>

## 풀링층의 역할과 종류를 설명해주세요.
<details>
  <summary>더보기</summary>
  **풀링층 (Pooling Layer):** 합성곱층에서 추출된 특징 맵을 다운샘플링하여 크기를 줄이고, 불변성을 증가시킵니다. 주요 종류는 최대 풀링(Max Pooling)과 평균 풀링(Average Pooling)입니다.
</details>

## 순환 신경망(RNN)이란 무엇이며, 어떤 문제에 사용되나요?
<details>
  <summary>더보기</summary>
  **순환 신경망 (Recurrent Neural Network, RNN):** 시계열 데이터나 순차 데이터를 처리하는 데 특화된 신경망입니다. 이전의 출력이 다음 입력으로 연결되어 시간적 종속성을 학습합니다. 예시: 자연어 처리, 주가 예측.
</details>

## LSTM과 GRU의 차이점은 무엇인가요?
<details>
  <summary>더보기</summary>
  - **LSTM (Long Short-Term Memory):** 장기 의존성을 학습하기 위해 게이트 구조를 가진 RNN입니다. 입력 게이트, 출력 게이트, 망각 게이트로 구성됩니다.
  - **GRU (Gated Recurrent Unit):** LSTM의 변형으로, 간단한 게이트 구조를 가지며 학습 속도가 빠릅니다. 업데이트 게이트와 리셋 게이트로 구성됩니다.
</details>

## 자연어 처리(NLP)에서 사용되는 임베딩이란 무엇인가요?
<details>
  <summary>더보기</summary>
  **임베딩 (Embedding):** 단어를 고차원 공간에 실수 벡터로 표현하는 기법입니다. 이를 통해 단어 간의 유사도를 계산할 수 있습니다. 예시: Word2Vec, GloVe.
</details>

## 주요 자연어 처리(NLP) 기법과 예시를 설명해주세요.
<details>
  <summary>더보기</summary>
  - **토큰화 (Tokenization):** 텍스트를 단어 또는 문자 단위로 나누는 것. 예시: 단어 토큰화, 문자 토큰화.
  - **형태소 분석 (Morphological Analysis):** 단어의 형태소를 분석하여 의미를 파악하는 것. 예시: 한국어 형태소 분석기.
  - **품사 태깅 (POS Tagging):** 단어의 품사를 태깅하는 것. 예시: 영어 품사 태깅.
  - **개체명 인식 (NER):** 텍스트에서 이름, 장소, 조직 등 고유 명사를 인식하는 것. 예시: NER 모델.
</details>

## 트랜스포머(Transformer) 모델이란 무엇이며, 어떤 특징이 있나요?
<details>
  <summary>더보기</summary>
  **트랜스포머 (Transformer):** 어텐션 메커니즘을 활용하여 순차적인 데이터의 종속성을 학습하는 모델입니다. RNN과 달리 병렬 처리가 가능하며, 자연어 처리에서 뛰어난 성능을 보입니다.
</details>

## BERT 모델이란 무엇이며, 어떻게 학습되나요?
<details>
  <summary>더보기</summary>
  **BERT (Bidirectional Encoder Representations from Transformers):** 양방향 트랜스포머를 사용하여 문맥을 학습하는 모델입니다. 마스킹된 언어 모델링(Masked Language Modeling)과 다음 문장 예측(Next Sentence Prediction)으로 사전 학습됩니다.
</details>

## GPT 모델이란 무엇이며, 어떻게 작동하나요?
<details>
  <summary>더보기</summary>
  **GPT (Generative Pre-trained Transformer):** 트랜스포머의 디코더를 기반으로 한 언어 생성 모델입니다. 대량의 텍스트 데이터를 사용하여 사전 학습된 후, 특정 작업에 맞게 미세 조정됩니다.
</details>

## 토큰화(Tokenization)란 무엇이며, 어떤 종류가 있나요?
<details>
  <summary>더보기</summary>
  **토큰화 (Tokenization):** 텍스트를 단어, 구, 문자 등으로 나누는 과정입니다.
  
  - **단어 토큰화:** 텍스트를 단어 단위로 나눔.
  - **문자 토큰화:** 텍스트를 문자 단위로 나눔.
  - **서브워드 토큰화:** 단어를 더 작은 단위(서브워드)로 나눔. 예시: BPE(Byte Pair Encoding), WordPiece.
</details>

## 스태킹(Stacking)이란 무엇인가요?
<details>
  <summary>더보기</summary>
  **스태킹 (Stacking):** 여러 개의 모델을 결합하여 예측 성능을 향상시키는 앙상블 방법입니다. 각 모델의 예측 결과를 메타 모델의 입력으로 사용합니다.
</details>

## 하이퍼파라미터 최적화 방법에는 어떤 것들이 있나요?
<details>
  <summary>더보기</summary>
  - **그리드 서치 (Grid Search):** 모든 하이퍼파라미터 조합을 시도하여 최적의 조합을 찾습니다.
  - **랜덤 서치 (Random Search):** 무작위로 하이퍼파라미터 조합을 시도하여 최적의 조합을 찾습니다.
  - **베이지안 최적화 (Bayesian Optimization):** 이전 시도의 결과를 바탕으로 다음 시도의 하이퍼파라미터를 선택합니다.
</details>

## 특성 선택(feature selection)이란 무엇이며, 어떤 방법들이 있나요?
<details>
  <summary>더보기</summary>
  **특성 선택 (Feature Selection):** 모델 성능을 향상시키기 위해 중요한 특성을 선택하는 과정입니다.
  
  - **필터 방법 (Filter Method):** 통계적 방법을 사용하여 특성을 선택합니다. 예시: 분산 임계값, 상관계수.
  - **랩퍼 방법 (Wrapper Method):** 모델 성능을 기준으로 특성을 선택합니다. 예시: 전진 선택법, 후진 제거법.
  - **임베디드 방법 (Embedded Method):** 모델 학습 과정에서 특성을 선택합니다. 예시: LASSO, 의사결정트리 기반 방법.
</details>

## 과적합(overfitting)과 과소적합(underfitting)의 차이점은 무엇인가요?
<details>
  <summary>더보기</summary>
  - **과적합 (Overfitting):** 학습 데이터에 너무 잘 맞춰져 새로운 데이터에 대한 일반화 성능이 떨어지는 상태.
  - **과소적합 (Underfitting):** 모델이 학습 데이터의 패턴을 충분히 학습하지 못하여 성능이 낮은 상태.
</details>

## 배치 정규화(batch normalization)의 원리와 장점을 설명해주세요.
<details>
  <summary>더보기</summary>
  **배치 정규화 (Batch Normalization):** 각 배치의 입력을 정규화하여 학습 속도를 높이고, 과적합을 방지합니다. 이를 통해 학습이 안정되고, 초기화에 덜 민감해집니다.
</details>

## 오토인코더(autoencoder)란 무엇이며, 어떤 용도로 사용되나요?
<details>
  <summary>더보기</summary>
  **오토인코더 (Autoencoder):** 입력을 압축된 표현으로 인코딩한 후, 이를 다시 원래의 입력으로 복원하는 신경망입니다. 차원 축소, 이상 탐지, 데이터 생성 등에 사용됩니다.
</details>

## GAN(Generative Adversarial Network)의 원리와 특징을 설명해주세요.
<details>
  <summary>더보기</summary>
  **GAN (Generative Adversarial Network):** 생성자(Generator)와 판별자(Discriminator)라는 두 개의 신경망이 경쟁하면서 학습하는 모델입니다. 생성자는 진짜 같은 데이터를 생성하고, 판별자는 진짜 데이터와 가짜 데이터를 구분합니다.
</details>

## 강화학습이란 무엇이며, 어떤 특징이 있나요?
<details>
  <summary>더보기</summary>
  **강화학습 (Reinforcement Learning):** 에이전트가 환경과 상호작용하며 보상을 최대화하는 행동을 학습하는 방법입니다. 주요 특징은 탐험과 활용의 균형을 맞추고, 장기적인 보상을 고려한다는 점입니다.
</details>

## Q-러닝(Q-learning)과 딥 Q-네트워크(DQN)의 차이점은 무엇인가요?
<details>
  <summary>더보기</summary>
  - **Q-러닝:** 테이블을 사용하여 상태-행동 값(Q-value)을 업데이트합니다.
  - **DQN (Deep Q-Network):** 신경망을 사용하여 상태-행동 값을 근사합니다. 대규모 상태 공간에서도 효과적으로 학습할 수 있습니다.
</details>

## 모델 기반 강화학습(model-based reinforcement learning)과 모델프리 강화학습(model-free reinforcement learning)의 차이점은 무엇인가요?
<details>
  <summary>더보기</summary>
  - **모델 기반 강화학습:** 환경 모델을 사용하여 학습합니다. 미래 상태를 예측하고, 최적의 행동을 결정합니다.
  - **모델프리 강화학습:** 환경 모델 없이 직접 학습합니다. 경험을 통해 최적의 정책을 학습합니다.
</details>

## 시계열 예측(time series forecasting)에서 사용되는 주요 머신러닝 기법을 설명해주세요.
<details>
  <summary>더보기</summary>
  - **ARIMA (AutoRegressive Integrated Moving Average):** 과거 데이터의 패턴을 이용하여 미래 값을 예측합니다.
  - **LSTM (Long Short-Term Memory):** 순환 신경망의 일종으로, 장기적인 종속성을 학습하여 시계열 데이터를 예측합니다.
  - **Prophet:** 페이스북에서 개발한 시계열 예측 라이브러리로, 휴일과 계절성을 고려하여 예측합니다.
</details>
